{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Define helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_names(df):\n",
    "    return df.rename(columns=lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "def auto_adjust_column_width(worksheet):\n",
    "    for column in worksheet.columns:\n",
    "        max_length = 0\n",
    "        column_letter = get_column_letter(column[0].column)\n",
    "        for cell in column:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(cell.value)\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = (max_length + 2) * 1.2\n",
    "        worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "def format_as_table(worksheet, data_range, style='TableStyleMedium9'):\n",
    "    table_name = re.sub(r'\\W+', '', worksheet.title)\n",
    "    table_name = f\"Table_{table_name}\"\n",
    "    \n",
    "    table = Table(displayName=table_name, ref=data_range)\n",
    "    style = TableStyleInfo(name=style, showFirstColumn=False,\n",
    "                           showLastColumn=False, showRowStripes=True, showColumnStripes=False)\n",
    "    table.tableStyleInfo = style\n",
    "    \n",
    "    worksheet.add_table(table)\n",
    "\n",
    "def add_total_row(worksheet):\n",
    "    last_row = worksheet.max_row\n",
    "    last_col = worksheet.max_column\n",
    "    \n",
    "    # Find the 'Amount' column\n",
    "    amount_col = None\n",
    "    for col in range(1, last_col + 1):\n",
    "        if worksheet.cell(row=1, column=col).value == 'Amount':\n",
    "            amount_col = col\n",
    "            break\n",
    "    \n",
    "    if amount_col is not None:\n",
    "        # Add 'Total' in the first column of the last row\n",
    "        worksheet.cell(row=last_row + 1, column=1, value='Total')\n",
    "        \n",
    "        # Add sum formula in the 'Amount' column\n",
    "        sum_formula = f'=SUM({get_column_letter(amount_col)}2:{get_column_letter(amount_col)}{last_row})'\n",
    "        worksheet.cell(row=last_row + 1, column=amount_col, value=sum_formula)\n",
    "        \n",
    "        # Make the total row bold\n",
    "        for col in range(1, last_col + 1):\n",
    "            worksheet.cell(row=last_row + 1, column=col).font = Font(bold=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel files\n",
    "file1_path = os.path.join(\"AR_Files\", \"AR_updated.xlsx\")\n",
    "file2_path = os.path.join(\"AR_Files\", \"PC_Overview_AR.xlsx\")\n",
    "new_file_path = os.path.join(\"AR_Files\", \"AR_Analysis.xlsx\")\n",
    "\n",
    "# Read PO Amount By Category sheet\n",
    "df1 = pd.read_excel(file1_path, sheet_name=\"last_updated\")\n",
    "\n",
    "# Read AR & AP Real 0804 sheet\n",
    "df2 = pd.read_excel(file2_path, sheet_name=\"AR & AP Real 0804\")\n",
    "\n",
    "df2 = clean_column_names(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dw/bhr69rw54bxf64hpjy8fb8fc0000gn/T/ipykernel_9844/2375834119.py:42: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_updated = pd.concat([df_updated, df_new_entries], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved: AR_Files/AR_Analysis.xlsx\n",
      "Number of new PO numbers added: 0\n",
      "\n",
      "Columns in Updated PO Data:\n",
      "['Type', 'Project #', 'Project Name', 'PO #', 'Total Contract $', 'Main Page', 'CO/Added', 'Amy PO ']\n"
     ]
    }
   ],
   "source": [
    "# Convert 'PO #' to string in both dataframes\n",
    "df1['PO #'] = df1['PO #'].astype(str)\n",
    "df2['tsmc PO #'] = df2['tsmc PO #'].astype(str)\n",
    "\n",
    "# Rename columns in df2 to match df1\n",
    "df2 = df2.rename(columns={\n",
    "    'tsmc PO #': 'PO #',\n",
    "    'System': 'Main Page',  # Note the space at the end to match df1\n",
    "    'PO Amount': 'Total Contract $'  # New mapping\n",
    "})\n",
    "\n",
    "# Filter df2 to include only 'Base Build' type\n",
    "df2_filtered = df2[df2['TSMC Depart'] == '新工']\n",
    "\n",
    "# Identify new PO numbers\n",
    "new_pos = set(df2_filtered['PO #']) - set(df1['PO #'])\n",
    "\n",
    "# Create a new dataframe for updated data\n",
    "df_updated = df1.copy()\n",
    "\n",
    "# Create a dataframe for new entries\n",
    "df_new_entries = pd.DataFrame(columns=df_updated.columns)\n",
    "\n",
    "# Update existing entries and collect new ones\n",
    "for index, row in df2_filtered.iterrows():\n",
    "    if row['PO #'] in df_updated['PO #'].values:\n",
    "        # Update existing entry\n",
    "        mask = df_updated['PO #'] == row['PO #']\n",
    "        for col in ['Main Page', 'Project #', 'Project Name', 'Total Contract $']:\n",
    "            if col in df2_filtered.columns and col in df_updated.columns:\n",
    "                if pd.notna(row[col]) and (pd.isna(df_updated.loc[mask, col]).any() or df_updated.loc[mask, col].iloc[0] == ''):\n",
    "                    df_updated.loc[mask, col] = row[col]\n",
    "    elif row['PO #'] in new_pos:\n",
    "        # Collect new entry\n",
    "        new_row = pd.DataFrame([row[['PO #', 'Main Page', 'Project #', 'Project Name', 'Total Contract $']]])\n",
    "        df_new_entries = pd.concat([df_new_entries, new_row], ignore_index=True)\n",
    "\n",
    "# Sort only the new entries by PO #\n",
    "df_new_entries = df_new_entries.sort_values('PO #')\n",
    "\n",
    "# Concatenate the original (updated) dataframe with the sorted new entries\n",
    "df_updated = pd.concat([df_updated, df_new_entries], ignore_index=True)\n",
    "\n",
    "# Write all sheets to the new Excel file\n",
    "with pd.ExcelWriter(new_file_path, engine='openpyxl') as writer:\n",
    "    df1.to_excel(writer, sheet_name=\"PO Amount By Category\", index=False)\n",
    "    df2.to_excel(writer, sheet_name=\"AR & AP Real 0804\", index=False)\n",
    "    df_updated.to_excel(writer, sheet_name=\"Updated PO Data\", index=False)\n",
    "\n",
    "    # Get the workbook to apply formatting\n",
    "    workbook = writer.book\n",
    "\n",
    "    for sheet_name in workbook.sheetnames:\n",
    "        worksheet = workbook[sheet_name]\n",
    "        auto_adjust_column_width(worksheet)\n",
    "        format_as_table(worksheet, f\"A1:{get_column_letter(worksheet.max_column)}{worksheet.max_row}\")\n",
    "        if sheet_name == \"Updated PO Data\":\n",
    "            add_total_row(worksheet)\n",
    "\n",
    "print(f\"Updated file saved: {new_file_path}\")\n",
    "print(f\"Number of new PO numbers added: {len(new_pos)}\")\n",
    "\n",
    "# Print the columns of df_updated to verify\n",
    "print(\"\\nColumns in Updated PO Data:\")\n",
    "print(df_updated.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Updated PO Data to AR_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting AR sheet update process...\n",
      "\n",
      "Found 0 new rows to add to last_updated sheet.\n",
      "No new rows found to add.\n"
     ]
    }
   ],
   "source": [
    "def update_ar_sheet():\n",
    "    # File paths\n",
    "    source_file = os.path.join(\"AR_Files\", \"AR_Analysis.xlsx\")\n",
    "    dest_file = os.path.join(\"AR_Files\", \"AR_updated.xlsx\")\n",
    "    \n",
    "    # Read both files\n",
    "    updated_po_data = pd.read_excel(source_file, sheet_name='Updated PO Data')\n",
    "    ar_data = pd.read_excel(dest_file, sheet_name='last_updated')\n",
    "    \n",
    "    # Convert PO numbers to string in both dataframes\n",
    "    updated_po_data['PO #'] = updated_po_data['PO #'].astype(str)\n",
    "    ar_data['PO #'] = ar_data['PO #'].astype(str)\n",
    "    \n",
    "    # Find new rows\n",
    "    new_rows = updated_po_data[~updated_po_data['PO #'].isin(ar_data['PO #'])]\n",
    "    \n",
    "    # Show information and get confirmation\n",
    "    print(f\"\\nFound {len(new_rows)} new rows to add to last_updated sheet.\")\n",
    "    if len(new_rows) > 0:\n",
    "        print(\"\\nSample PO numbers to be added:\")\n",
    "        sample_size = min(5, len(new_rows))  # Show up to 5 samples\n",
    "        for po in new_rows['PO #'].head(sample_size):\n",
    "            print(f\"- {po}\")\n",
    "        \n",
    "        confirm = input(\"\\nDo you want to proceed with updating the last_updated sheet? (yes/no): \").lower()\n",
    "        \n",
    "        if confirm != 'yes':\n",
    "            print(\"Update cancelled.\")\n",
    "            return\n",
    "        \n",
    "        # Proceed with update if confirmed\n",
    "        with pd.ExcelWriter(dest_file, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "            # Append new rows to existing data\n",
    "            updated_ar = pd.concat([ar_data, new_rows], ignore_index=True)\n",
    "            \n",
    "            # Write back to last_updated sheet\n",
    "            updated_ar.to_excel(writer, sheet_name='last_updated', index=False)\n",
    "            \n",
    "            print(f\"\\nSuccessfully added {len(new_rows)} new rows to last_updated sheet\")\n",
    "    else:\n",
    "        print(\"No new rows found to add.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting AR sheet update process...\")\n",
    "    update_ar_sheet()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
