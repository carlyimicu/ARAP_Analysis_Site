{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add New PC_Overview Rows to All Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data and removed rows saved to AP_Files/All_Stack_Filtered.xlsx\n",
      "Rows removed from Stack: 73\n",
      "Rows removed from pc_overview: 73\n"
     ]
    }
   ],
   "source": [
    "def filter_sheets(input_file_path, output_file_path, po_numbers_to_exclude):\n",
    "    # Read the Excel file\n",
    "    with pd.ExcelFile(input_file_path) as xls:\n",
    "        df_stack = pd.read_excel(xls, \"Stack\")\n",
    "        df_pc_overview = pd.read_excel(xls, \"pc_overview\")\n",
    "\n",
    "    # Filter out rows with the specified PO numbers and keep the removed rows\n",
    "    df_stack_filtered = df_stack[~df_stack[\"PO #\"].isin(po_numbers_to_exclude)]\n",
    "    df_stack_removed = df_stack[df_stack[\"PO #\"].isin(po_numbers_to_exclude)]\n",
    "\n",
    "    df_pc_overview_filtered = df_pc_overview[~df_pc_overview[\"PO #\"].isin(po_numbers_to_exclude)]\n",
    "    df_pc_overview_removed = df_pc_overview[df_pc_overview[\"PO #\"].isin(po_numbers_to_exclude)]\n",
    "\n",
    "    # Save the filtered data and removed rows to a new Excel file\n",
    "    with pd.ExcelWriter(output_file_path, engine='openpyxl') as writer:\n",
    "        df_stack_filtered.to_excel(writer, sheet_name=\"Stack\", index=False)\n",
    "        df_pc_overview_filtered.to_excel(writer, sheet_name=\"pc_overview\", index=False)\n",
    "        df_stack_removed.to_excel(writer, sheet_name=\"Stack_Removed\", index=False)\n",
    "        df_pc_overview_removed.to_excel(writer, sheet_name=\"pc_overview_Removed\", index=False)\n",
    "\n",
    "    print(f\"Filtered data and removed rows saved to {output_file_path}\")\n",
    "    print(f\"Rows removed from Stack: {len(df_stack_removed)}\")\n",
    "    print(f\"Rows removed from pc_overview: {len(df_pc_overview_removed)}\")\n",
    "\n",
    "# Updated PO numbers to exclude\n",
    "po_numbers_to_exclude = [\n",
    "    \"USCSB2307079A\", \"USCSB2308094A\", \"USCSB2109007A\", \"USCSB2306043A\", \"USCSB2205003A\",\n",
    "    \"USCSB2306078A\", \"USCSB2306029A\", \"USCSB2403154A\", \"USCSB2305094A\", \"USC2301008A\",\n",
    "    \"USCSB2306077A\", \"USCSB2307120A\", \"USCSB2307121A\", \"USCSB2205007A\", \"USCSB2301045A\",\n",
    "    \"USCSB2406081A\", \"USCSB2405066A\", \"USCSB2405061A\", \"USCSB2308142A\", \"USCSB2308173A\",\n",
    "    \"USCSB2301026A\", \"USCSB2208007A\", \"USCSB2306120A\", \"USCSB2309112A\", \"USCSB2306130A\",\n",
    "    \"USCSB2404182A\", \"USCSB2408133A\", \"USCSB2307113A\", \"USCSB2405142A\", \"USCSB2308177A\",\n",
    "    \"USCSB2305079A\", \"USCSB2205026A\", \"USCSB2404156A\", \"USCSB2404097A\", \"USCSB2205016A\",\n",
    "    \"USCSB2405089A\", \"USCSB2312149A\", \"USCSB2302056A\", \"USCSB2306102A\", \"USCSB2406056A\",\n",
    "    \"USCSB2403037A\", \"USCSB2404139A\", \"USCSB2307024A\", \"USCSB2404040A\", \"USCSB2310090A\",\n",
    "    \"USCSB2306049A\", \"USCSB2402195A\", \"USCSB2402086A\", \"USCSB2308180A\", \"USCSB2402151A\",\n",
    "    \"USCSB2405032A\", \"USCSB2309010A\", \"USCSB2310055A\", \"USCSB2308050A\", \"USCSB2310139A\",\n",
    "    \"USCSB2402210A\", \"USCSB2403180A\", \"USCSB2407146A\", \"USCSB2405102A\", \"USCSB2310170A\",\n",
    "    \"USC2111048A\", \"USC2309038B\", \"USCSB2310116A\", \"USCSB2212045A\", \"USCSB2308004A\",\n",
    "    \"USCSB2407117A\", \"USCSB2309026A\", \"USCSB2404022A\", \"USC2402072A\", \"USCSB2308070A\",\n",
    "    \"USCSB2407090A\", \"USCSB2406116A\", \"USCSB2401044A\"\n",
    "]\n",
    "\n",
    "# File paths using os.path.join() for cross-platform compatibility\n",
    "input_file_path = os.path.join('AP_Files', 'All_Stack.xlsx')\n",
    "output_file_path = os.path.join('AP_Files', 'All_Stack_Filtered.xlsx')\n",
    "\n",
    "\n",
    "# Run the function\n",
    "filter_sheets(input_file_path, output_file_path, po_numbers_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary tables have been updated and saved to AP_Files/updated_all_stack.xlsx\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "ALL_STACK_PATH = os.path.join(\"AP_Files\", \"All_Stack_Filtered.xlsx\")\n",
    "OUTPUT_PATH = os.path.join(\"AP_Files\", \"updated_all_stack.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def auto_adjust_column_width(worksheet):\n",
    "    for column in worksheet.columns:\n",
    "        max_length = 0\n",
    "        column_letter = get_column_letter(column[0].column)\n",
    "        for cell in column:\n",
    "            try:\n",
    "                if len(str(cell.value)) > max_length:\n",
    "                    max_length = len(cell.value)\n",
    "            except:\n",
    "                pass\n",
    "        adjusted_width = (max_length + 2) * 1.2\n",
    "        worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "def format_as_table(worksheet, data_range, style='TableStyleMedium9'):\n",
    "    table_name = re.sub(r'\\W+', '', worksheet.title)\n",
    "    table_name = f\"Table_{table_name}\"\n",
    "    \n",
    "    table = Table(displayName=table_name, ref=data_range)\n",
    "    style = TableStyleInfo(name=style, showFirstColumn=False,\n",
    "                           showLastColumn=False, showRowStripes=True, showColumnStripes=False)\n",
    "    table.tableStyleInfo = style\n",
    "    \n",
    "    worksheet.add_table(table)\n",
    "\n",
    "def add_total_row(worksheet):\n",
    "    last_row = worksheet.max_row\n",
    "    last_col = worksheet.max_column\n",
    "    \n",
    "    amount_col = None\n",
    "    for col in range(1, last_col + 1):\n",
    "        if worksheet.cell(row=1, column=col).value == 'Sum of Amount':\n",
    "            amount_col = col\n",
    "            break\n",
    "    \n",
    "    if amount_col is not None:\n",
    "        worksheet.cell(row=last_row + 1, column=1, value='Total')\n",
    "        sum_formula = f'=SUM({get_column_letter(amount_col)}2:{get_column_letter(amount_col)}{last_row})'\n",
    "        worksheet.cell(row=last_row + 1, column=amount_col, value=sum_formula)\n",
    "        \n",
    "        for col in range(1, last_col + 1):\n",
    "            worksheet.cell(row=last_row + 1, column=col).font = Font(bold=True)\n",
    "\n",
    "def process_data():\n",
    "    # Read data from All Stack Analysis\n",
    "    pc_overview = pd.read_excel(ALL_STACK_PATH, sheet_name=\"pc_overview\")\n",
    "    stack_data = pd.read_excel(ALL_STACK_PATH, sheet_name=\"Stack\")\n",
    "    \n",
    "    # Identify new rows in pc_overview that are not in stack_data\n",
    "    new_rows = pc_overview[~pc_overview['PO #'].isin(stack_data['PO #'])]\n",
    "\n",
    "    # Prepare new rows for Stack\n",
    "    new_stack_rows = new_rows[['Project Number', 'PO #', 'PO Description', 'Vendor/Subcontractor', 'Amount']].copy()\n",
    "    # new_stack_rows = new_stack_rows.rename(columns={\n",
    "    #     'Amount': 'Sum of Amount'\n",
    "    # })\n",
    "\n",
    "    # Append new rows to stack_data\n",
    "    stack_data_updated = pd.concat([stack_data, new_stack_rows], ignore_index=True)\n",
    "\n",
    "    return stack_data_updated\n",
    "\n",
    "def create_summary_sheets(stack_data, writer):\n",
    "    # Write the updated Stack sheet as pc_overview in the summary file\n",
    "    stack_data.to_excel(writer, sheet_name='pc_overview', index=False)\n",
    "    worksheet = writer.sheets['pc_overview']\n",
    "    auto_adjust_column_width(worksheet)\n",
    "    format_as_table(worksheet, f\"A1:{get_column_letter(worksheet.max_column)}{worksheet.max_row}\")\n",
    "    # add_total_row(worksheet)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Process data\n",
    "    updated_stack_data = process_data()\n",
    "\n",
    "    # Create summary sheets\n",
    "    with pd.ExcelWriter(OUTPUT_PATH, engine='openpyxl') as writer:\n",
    "        create_summary_sheets(updated_stack_data, writer)\n",
    "\n",
    "    print(f\"Summary tables have been updated and saved to {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Manually Updated Stack Sheet to All Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Stack sheet update process...\n",
      "\n",
      "Found 102 new rows to add to Stack sheet.\n",
      "First new PO #: US2SB2410003A\n",
      "Update cancelled.\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "ALL_STACK_PATH = os.path.join(\"AP_Files\", \"All_Stack.xlsx\")\n",
    "OUTPUT_PATH = os.path.join(\"AP_Files\", \"updated_all_stack.xlsx\")\n",
    "\n",
    "def update_stack_sheet():\n",
    "    # Read both files\n",
    "    summary_data = pd.read_excel(OUTPUT_PATH, sheet_name='pc_overview')\n",
    "    stack_data = pd.read_excel(ALL_STACK_PATH, sheet_name='Stack')\n",
    "    \n",
    "    # Find rows in summary_data where PO # is not in stack_data\n",
    "    new_rows = summary_data[~summary_data['PO #'].isin(stack_data['PO #'])]\n",
    "    \n",
    "    # Show information and get confirmation\n",
    "    print(f\"\\nFound {len(new_rows)} new rows to add to Stack sheet.\")\n",
    "    if len(new_rows) > 0:\n",
    "        sample_po = new_rows['PO #'].iloc[0]\n",
    "        print(f\"First new PO #: {sample_po}\")\n",
    "        \n",
    "        confirm = input(\"\\nDo you want to proceed with updating the Stack sheet? (yes/no): \").lower()\n",
    "        \n",
    "        if confirm != 'yes':\n",
    "            print(\"Update cancelled.\")\n",
    "            return\n",
    "        \n",
    "        # Proceed with update if confirmed\n",
    "        with pd.ExcelWriter(ALL_STACK_PATH, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            # Append new rows to stack_data\n",
    "            updated_stack = pd.concat([stack_data, new_rows], ignore_index=True)\n",
    "            \n",
    "            # Write back to Stack sheet\n",
    "            updated_stack.to_excel(writer, sheet_name='Stack', index=False)\n",
    "            \n",
    "            print(f\"\\nSuccessfully added {len(new_rows)} new rows to Stack sheet\")\n",
    "    else:\n",
    "        print(\"No new rows found to add.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Stack sheet update process...\")\n",
    "    update_stack_sheet()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
